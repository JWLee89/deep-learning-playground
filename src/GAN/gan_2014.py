import tensorflow as tf
import numpy as np
from tensorflow.examples.tutorials.mnist import input_data
import matplotlib.pyplot as plt

"""
    Author: Jay Lee
    A simple GAN implementation based off Ian Goodfellow's paper:
    Generative Adversarial Networks
"""

def get_noise(batch_size, noise_size):
    """
    :param batch_size: The number of items in the batch. For this
    exercise, will be 200
    :param noise_size: The size of the noise for each given image to generate.
    For this example, value is 128/
    :return:
    """
    return np.random.normal(size=(batch_size, noise_size))


def layer(input_tensor, units):
    """
    Simple utility function to create a layer in a
    feedforward network
    :param input_tensor: The input to the current layer
    :param units: The number of units in the current layer
    :return:
    """
    input_size = input_tensor.get_shape().as_list()
    W = tf.get_variable(name="W", shape=(input_size[1], units), dtype=tf.float32,
                        initializer=tf.contrib.layers.xavier_initializer())
    b = tf.get_variable(name="b", shape=(units, ), dtype=tf.float32,
                        initializer=tf.constant_initializer(0))
    return tf.matmul(input_tensor, W) + b


def generator(random_noise, layers=[256, 784]):
    """
        :param random_noise:
        Receive an input of dimensions (batch_size, noise_size)
        :param layers: The number of units in each layer.
        The final layer is the output layer of the network.
        :return:
    """
    with tf.variable_scope("generator"):
        current_layer = random_noise
        for i in range(len(layers) - 1):
            with tf.variable_scope(f"layer_{i + 1}"):
                current_layer = tf.nn.relu(layer(current_layer, layers[i]))
        with tf.variable_scope("output"):
            output = tf.nn.tanh(layer(current_layer, layers[-1]))
            return output


def discriminator(input_tensor, layers=[256, 1], reuse=False):
    """
        Receive an input of dimensions (batch_size, noise_size)
        All layers use leaky relu activation except for output,
        which uses sigmoid, since the output values must range
        between 0 and 1
        :param input_tensor: An image. Can be real or generated by
        the generator.
        :param layers: The number of units in each layer.
        The final layer is the output layer of the network.
        :param reuse: A boolean flag indicating whether to re-use
        weights. used since we create two computational graphs:
        one for receiving fake images, the other for receiving
        batches of mmnist images directly.
        :return:
    """
    with tf.variable_scope("discriminator", reuse=reuse):
        current_layer = input_tensor
        for i in range(len(layers) - 1):
            with tf.variable_scope(f"layer_{i + 1}"):
                current_layer = tf.nn.leaky_relu(layer(current_layer, layers[i]), alpha=0.2)
        with tf.variable_scope("output"):
            output = tf.nn.sigmoid(layer(current_layer, 1))
            return output


def get_train_op(real_img_prob, fake_img_prob, lr=0.0002):
    """
        :param real_img_prob: Probability of the real image
        being interpreted as a real image
        :param fake_img_prob: Probability of fake image being
        interpreted as fake.
        :param lr: Learning rate
        :return:
    """
    # we need to get the variables for generator and discriminator
    # So that we can fix parameters of generator when training discriminator
    generator_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, "generator")
    discriminator_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, "discriminator")

    # Cost functions as specified in paper
    # tf.log(1 - fake_image_prob) becomes high as fake_image_prob reaches close to 0.
    # If close to 1, discriminator is able to effectively tell fakes

    discriminator_cost = -tf.reduce_mean(tf.log(real_img_prob) + tf.log(1 - fake_img_prob))
    generator_cost = -tf.reduce_mean(tf.log(fake_img_prob))

    # training operations
    train_discriminator = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5) \
        .minimize(discriminator_cost, var_list=discriminator_vars)
    train_generator = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5) \
        .minimize(generator_cost, var_list=generator_vars)

    return train_discriminator, train_generator, discriminator_cost, generator_cost


if __name__ == '__main__':

    with tf.Graph().as_default():
        # Read data
        data = input_data.read_data_sets(train_dir="./data/", one_hot=True)
        train, validation, test = data

        x_train, y_train = train.images, train.labels
        x_validation, y_validation = validation.images, validation.labels
        x_test, y_test = test.images, test.labels

        x_train, x_test, x_validation = np.array(x_train), \
                                        np.array(x_test), np.array(x_validation)

        # Hyper parameter - Very sensitive to it
        # So make sure that we pick values wisely
        # Try experimenting with these values
        learning_rate = 0.0002
        epoch_count = 200
        batch_size = 200
        image_size = 28
        vectorized_image_size = image_size * image_size
        noise_size = 128
        hidden_units = 256

        # Define tensorflow placeholders
        # Placeholder for actual image inputs
        X = tf.placeholder(name='X', shape=(None, vectorized_image_size), dtype=tf.float32)
        # Placeholder for actual image inputs
        Z = tf.placeholder(name='Z', shape=(None, noise_size), dtype=tf.float32)


        # Generator output
        generated_images = generator(Z)

        # Discriminator output
        fake_image_outputs = discriminator(generated_images, layers=[hidden_units, hidden_units, vectorized_image_size], reuse=False)
        real_image_outputs = discriminator(X, layers=[hidden_units, hidden_units, 1], reuse=True)

        # Train op and cost functions
        train_discriminator_op, train_generator_op, \
        discriminator_cost, generator_cost = get_train_op(real_image_outputs, fake_image_outputs, learning_rate)

        samples = []

        with tf.Session() as sess:
            init = tf.global_variables_initializer()
            sess.run(init)
            training_steps = len(x_train) // batch_size

            for epoch in range(1, epoch_count + 1):
                for step in range(training_steps):
                    indexes = np.random.choice(len(x_train), batch_size)
                    batch_images = x_train[indexes]
                    batch_z = get_noise(batch_size, noise_size)

                    # Train discriminator
                    _, disc_cost = sess.run([train_discriminator_op, discriminator_cost],
                                            feed_dict={Z: batch_z, X: batch_images})

                    # Train generator
                    _, gen_cost = sess.run([train_generator_op, generator_cost],
                                           feed_dict={Z: batch_z})

                # Cost on test_set
                batch_z = get_noise(len(x_test), noise_size)
                disc_cost = sess.run(discriminator_cost, feed_dict={Z: batch_z, X: x_test})
                gen_cost = sess.run(generator_cost, feed_dict={Z: batch_z})

                print('Epoch:', '%04d' % epoch,
                      'D loss: {:.4}'.format(disc_cost),
                      'G loss: {:.4}'.format(gen_cost))

                # Store images in mnist_output/
                if epoch == 0 or (epoch + 1) % 10 == 0:
                    sample_size = 10
                    noise = get_noise(sample_size, noise_size)
                    samples = sess.run(generated_images, feed_dict={Z: noise})

                    fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1))

                    for i in range(sample_size):
                        ax[i].set_axis_off()
                        ax[i].imshow(np.reshape(samples[i], (28, 28)))

                    # save image
                    plt.savefig('mnist_output/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')
                    plt.close(fig)
